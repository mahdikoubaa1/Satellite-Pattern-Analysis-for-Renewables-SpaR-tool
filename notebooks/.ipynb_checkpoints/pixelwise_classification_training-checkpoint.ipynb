{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import box\n",
    "from torchvision import  transforms\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from split_tiff import Split\n",
    "from rgb_js import rgbAdjustment\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from models.kmeans_pytorch import kmeans, kmeans_predict\n",
    "from matplotlib.lines import Line2D\n",
    "from pathlib import Path\n",
    "from models.clustering import KNN\n",
    "from models.faissknn import FaissKNeighbors\n",
    "from models.pixelwise_classification import pixelwise\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import torch.nn.functional as fn\n",
    "split=Split()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "r= torch.cuda.memory_reserved(0)\n",
    "print(f'memory allocated:{a/(1024.0*1024.0*1024.0)}/ memory reserved:{r/(1024.0*1024.0*1024.0)}')\n",
    "data_path= \"../data/testing_samples/\"\n",
    "onlyfiles = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from contextlib import closing\n",
    "import numpy as np\n",
    "\n",
    "with closing(sqlite3.connect('../data/sampled.gpkg')) as conn:\n",
    "    with closing(conn.cursor()) as cursor:\n",
    "        sql_query = \"\"\"SELECT name FROM sqlite_master  \n",
    "  WHERE type='table';\"\"\"\n",
    "        cursor.execute(sql_query)\n",
    "        h =cursor.fetchall()\n",
    "\n",
    "        files= []\n",
    "        sql_query = \"\"\"DROP VIEW IF EXISTS merged_view;\"\"\"\n",
    "        cursor.execute(sql_query)\n",
    "        conn.commit()\n",
    "        for k in h:\n",
    "            if k[0][0]=='e' : files.append (k[0])\n",
    "        print(files)\n",
    "        union_query= ''\n",
    "        if len(files)>0 :\n",
    "            sql_query= f\"DELETE from '{files[0]}' where SAMPLE_1 IS NULL;\"\n",
    "            cursor.execute(sql_query)\n",
    "            union_query += f\"create view merged_view as select * from '{files[0]}'\"\n",
    "        for  i in range(1,len(files)):\n",
    "            sql_query= f\"DELETE from '{files[i]}' where SAMPLE_1 is NULL;\"\n",
    "            cursor.execute(sql_query)\n",
    "\n",
    "\n",
    "            union_query+= f\" union select * from '{files[i]}'\"\n",
    "        union_query +=';'\n",
    "        cursor.execute(union_query)\n",
    "        sql_query= f\"select SAMPLE_1,SAMPLE_2,SAMPLE_3,SAMPLE_4,SAMPLE_5,SAMPLE_6,SAMPLE_7,SAMPLE_8,SAMPLE_9,SAMPLE_10,SAMPLE_11,SAMPLE_12,SAMPLE_13, label  from merged_view;\"\n",
    "\n",
    "        cursor.execute(sql_query)\n",
    "\n",
    "        res=cursor.fetchall()\n",
    "    \n",
    "        conn.commit()\n",
    "res = np.asarray(res)\n",
    "print (res)\n",
    "centers =res[:,0:13]\n",
    "centers=np.delete(centers,10,axis=1)\n",
    "centers=centers.astype('float32')\n",
    "labels = res[:,13]\n",
    "print (centers[0])\n",
    "print (res.shape)\n",
    "opts= {'epochs': 4000, 'input_bands':[i+1 for i in range(13)],'cutoff_area':(0.01),'points_per_polygon':10}\n",
    "opts[\"input_bands\"].remove(11)\n",
    "sampled_points=gpd.read_file(f\"../data/sampled_points.gpkg\")\n",
    "centers=np.array(sampled_points[[f\"{i}\"for i in opts['input_bands']]])\n",
    "print(centers[0])\n",
    "labels=np.array(sampled_points['label'])\n",
    "print (centers.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(onlyfiles)\n",
    "print(len(onlyfiles))\n",
    "onlyfiles= onlyfiles [0:1]\n",
    "print((onlyfiles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openImagesforcentroids(data_path,onlyfiles):\n",
    "    images= {}\n",
    "    for filename in tqdm(onlyfiles, desc=\"opening centroid images\"):\n",
    "        tiff = rasterio.open(f\"{data_path}/{filename}\")\n",
    "        band = tiff.read()\n",
    "        image = np.array(band,dtype='float64')\n",
    "        image=np.delete(image,10,axis=0)\n",
    "        image = np.moveaxis(image,0,2)\n",
    "        images.update({filename:image})\n",
    "    return images\n",
    "centimages=openImagesforcentroids(data_path,onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildLegend(colors):\n",
    "    legend_elements =[]\n",
    "    for i in range(len(colors)):\n",
    "        legend_elements.append(Line2D([0], [0], marker='o', color='w', label=f'Label_{i}',markerfacecolor=colors[i], markersize=20))\n",
    "    return legend_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting for kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_prediction(image,image_clustered,colors,filename):\n",
    "    '''\n",
    "    Plots and a slice with all available annotations\n",
    "    '''\n",
    "\n",
    "\n",
    "    legend_elements = BuildLegend(colors)\n",
    "    image = resize(image, (1200, 1200, 3), anti_aliasing=True)\n",
    "    image_clustered = resize(image_clustered, (1200, 1200, 3), anti_aliasing=True)\n",
    "    fig = plt.figure(figsize=(80, 80))\n",
    "    #flatui = [\"#3498db\", \"#651FFF\"]\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(filename)\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(image_clustered)\n",
    "    plt.axis(\"off\")\n",
    "    plt.legend(handles=legend_elements,bbox_to_anchor=(0,1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "def plot_sample_prediction_classification(image,pred,filename):\n",
    "    '''\n",
    "    Plots and a slice with all available annotations\n",
    "    '''\n",
    "    flatui = [\"#3498db\", \"#FFD700\"]\n",
    "\n",
    "    color_map = ListedColormap(sns.color_palette(flatui).as_hex())\n",
    "\n",
    "    image = resize(image, (1200, 1200, 3), anti_aliasing=True)\n",
    "    pred = resize(pred, (1200, 1200), anti_aliasing=True)\n",
    "    fig = plt.figure(figsize=(80, 80))\n",
    "    #flatui = [\"#3498db\", \"#651FFF\"]\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(filename)\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(image)\n",
    "    pred = np.ma.masked_where(pred == 0, pred)\n",
    "    plt.imshow(pred, alpha=0.5, interpolation='none', cmap=color_map, vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old kmeans/knn code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictClusters1(image_filepath,onlyfiles,cluster_centers,labels,mean,std,save=False):\n",
    "    t2rgb = rgbAdjustment()\n",
    "    for filename in tqdm(onlyfiles, desc=\"Predicting Clusters\"):\n",
    "        tiff = rasterio.open(f\"{image_filepath}/{filename}\")\n",
    "        band = tiff.read()\n",
    "        image1 = np.array(band,dtype='float64',order='C')\n",
    "        image= image1.reshape(13,-1)\n",
    "        image=np.delete(image,10,axis=0)\n",
    "\n",
    "        image = torch.from_numpy(image)\n",
    "        image.to('cuda')\n",
    "        image=torch.movedim ( image,0,1)\n",
    "        image=(image-mean)/std\n",
    "        cluster_ids = kmeans_predict(image,cluster_centers, 'euclidean', device=torch.device('cuda:0'))\n",
    "        clustered= labels[cluster_ids]\n",
    "\n",
    "        clustered=clustered.reshape(image1.shape[1],image1.shape[2],1)\n",
    "        rgb= np.asarray(t2rgb.evaluate_pixel(image1[3]/10000,image1[2]/10000,image1[1]/10000))\n",
    "        rgb_clustered=np.asarray(t2rgb.evaluate_pixel(clustered,clustered,clustered))\n",
    "\n",
    "        \n",
    "        if (save):\n",
    "            print('save not implemented')\n",
    "            #out_meta=tiff.meta\n",
    "            #Path(f\"{image_filepath}/clustered\").mkdir(parents=True, exist_ok=True)\n",
    "            #dest= rasterio.open(f\"{image_filepath}/clustered/clustered_{filename}\", \"w\", **out_meta)\n",
    "            #image=np.asarray(image,dtype='uint16')\n",
    "            #dest.write(image)\n",
    "\n",
    "        plot_sample_prediction_classification(rgb, rgb_clustered,filename)\n",
    "        \n",
    "\n",
    "def PredictClusters(image_filepath,onlyfiles,knn,mean,std,save=False):\n",
    "    t2rgb = rgbAdjustment()\n",
    "    for filename in tqdm(onlyfiles, desc=\"Predicting Clusters\"):\n",
    "        tiff = rasterio.open(f\"{image_filepath}/{filename}\")\n",
    "        band = tiff.read()\n",
    "        image1 = np.array(band,dtype='float32')\n",
    "        image= image1.reshape(13,-1)\n",
    "        image=np.delete(image,10,axis=0)\n",
    "\n",
    "        image=np.moveaxis ( image,0,1)\n",
    "        image=(image-mean)/std\n",
    "        print(image.shape)\n",
    "        clustered= knn.predict(image.copy(order='C'))\n",
    "        clustered=clustered.reshape(image1.shape[1],image1.shape[2],1)\n",
    "        rgb= np.asarray(t2rgb.evaluate_pixel(image1[3]/10000,image1[2]/10000,image1[1]/10000))\n",
    "        rgb_clustered=np.asarray(t2rgb.evaluate_pixel(clustered,clustered,clustered))\n",
    "        if (save):\n",
    "            clustered=clustered.expand(image1.shape[1],image1.shape[2],13)\n",
    "            clustered=torch.movedim(clustered,2,0)\n",
    "            print ('save not implemented')\n",
    "            out_meta=tiff.meta\n",
    "            Path(f\"{image_filepath}/clustered\").mkdir(parents=True, exist_ok=True)\n",
    "            dest= rasterio.open(f\"{image_filepath}/clustered/clustered_{filename}\", \"w\", **out_meta)\n",
    "            clustered=np.asarray(clustered,dtype='uint16')\n",
    "            \n",
    "            dest.write(clustered)\n",
    "        \n",
    "        plot_sample_prediction_classification(rgb, rgb_clustered,filename)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bandatcoordinates(centroids,centimages):\n",
    "    centers= []\n",
    "    labels=[]\n",
    "    for filename, x,y, label in tqdm(centroids, desc=\"getting centroids\"):\n",
    "        centers .append (centimages[filename][x][y])\n",
    "        labels.append(label)\n",
    "    labels=np.asarray(labels)\n",
    "    labels=torch.from_numpy(labels)\n",
    "    labels.to('cuda')\n",
    "    centers= np.asarray(centers)\n",
    "    centers= torch.from_numpy(centers)\n",
    "    centers.to('cuda')\n",
    "    return centers , labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainpixelwisenn(model,data,labels,normalize,epochs):\n",
    "    lossf=model.loss\n",
    "    oneh=np.asarray([[1,0],[0,1]])\n",
    "    labels=oneh[labels]\n",
    "    optimizer=model.optimizer\n",
    "    data=np.moveaxis(data,1,0)\n",
    "    labels=np.moveaxis(labels,1,0)\n",
    "\n",
    "    data= data.reshape((1,data.shape[0],-1,1))\n",
    "    labels= labels.astype('float32').reshape((1,2,-1,1))\n",
    "    data = torch.from_numpy(data.astype('float32'))\n",
    "    labels=torch.from_numpy(labels)\n",
    "    data=data.to('cuda:0')\n",
    "    normalize(data)\n",
    "    labels=labels.to('cuda:0')\n",
    "    model.train()\n",
    "    t= tqdm(range(epochs))\n",
    "    running_loss=0.\n",
    "    for i in t:\n",
    "        optimizer.zero_grad()\n",
    "        predictions= model(data)\n",
    "        loss=lossf(predictions,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss-=running_loss/(i+1)\n",
    "        running_loss+=loss/(i+1)\n",
    "        t.set_postfix_str(f'training loss:{running_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifypixelwise(image_filepath,onlyfiles,pixelwisenn,normalize,save=False,plot=False):\n",
    "    t2rgb = rgbAdjustment()\n",
    "    pixelwisenn.eval()\n",
    "    for filename in tqdm(onlyfiles, desc=\"Predicting Clusters\"):\n",
    "        tiff = rasterio.open(f\"{image_filepath}/{filename}\")\n",
    "        band = tiff.read()\n",
    "        image1 = np.array(band,dtype='float32')\n",
    "        image=np.delete(image1,10,axis=0)\n",
    "        image=image.reshape(1,image.shape[0],image.shape[1],image.shape[2])\n",
    "        image=torch.from_numpy(image)\n",
    "        image=image.to('cuda:0')\n",
    "        normalize(image)\n",
    "        clustered=pixelwisenn.predict(image)\n",
    "        clustered=clustered.reshape(image1.shape[1],image.shape[2])\n",
    "        clustered =clustered.cpu().detach().numpy()\n",
    "        pred=clustered.astype('uint8')\n",
    "        rgb= np.asarray(t2rgb.evaluate_pixel(image1[3]/10000,image1[2]/10000,image1[1]/10000))\n",
    "        shapes = rasterio.features.shapes(pred, transform=tiff.transform)\n",
    "        records = [{\"geometry\": shape(geometry), \"properties\": {\"value\": value}}\n",
    "           for (geometry, value) in shapes if value == 1]\n",
    "        geojson=gpd.GeoDataFrame(records)\n",
    "        geojson=geojson[geojson[\"geometry\"].area>(30*1.3266831467881673e-08)]\n",
    "        if (save):\n",
    "            \n",
    "            shpfilename= filename.replace(\".tiff\", \".GeoJSON\")\n",
    "            geojson.to_file(f\"{image_filepath}/clustered/clustered_{shpfilename}\", driver='GeoJSON',crs=tiff.crs.data)  \n",
    "\n",
    "            #out_meta=tiff.meta\n",
    "            #Path(f\"{image_filepath}/clustered\").mkdir(parents=True, exist_ok=True)\n",
    "            #dest= rasterio.open(f\"{image_filepath}/clustered/clustered_{filename}\", \"w\", **out_meta)\n",
    "            #clustered=np.asarray(clustered,dtype='uint16')\n",
    "            #dest.write(clustered)\n",
    "\n",
    "        if (plot):\n",
    "\n",
    "            if (len (geojson[\"geometry\"])==0): pred = np.zeros((1200,1200))\n",
    "            else:\n",
    "                pred, _ = mask(tiff,geojson[\"geometry\"] , crop=False)\n",
    "                pred = np.where(pred!= 0, 1., pred)\n",
    "                pred = pred[0]\n",
    "            plot_sample_prediction_classification(rgb, pred,filename)\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old kmeans/knn code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images1= split.ExtractImages_imagesonly(data_path,onlyfiles)\n",
    "#images= np.concatenate(images1,1)\n",
    "\n",
    "#images=np.delete(images,10,axis=0)\n",
    "\n",
    "#images = torch.from_numpy(images)\n",
    "\n",
    "#images.to('cuda')\n",
    "#mean= torch.mean(images,1)\n",
    "\n",
    "#std= torch.std(images,1)\n",
    "#images=torch.movedim ( images,0,1)\n",
    "#images=(images -mean)/std\n",
    "\n",
    "#centers,labels = Bandatcoordinates([\n",
    "#                             ('e_51.72116_11.949889.tiff',560,821,1),\n",
    "#                             ('e_51.72116_11.949889.tiff',606,688,1),\n",
    "#                             ('e_51.72116_11.949889.tiff',750,241,0),\n",
    "#                             ('e_51.72116_11.949889.tiff',274,844,0),\n",
    "#                             ('e_51.72116_11.949889.tiff',590,823,1),\n",
    "#                             ('e_52.693698_14.239078.tiff',512,662,0),\n",
    "#                             ('e_52.693698_14.239078.tiff',481,555,0),\n",
    "#                             ('e_51.539586_13.956551.tiff',598,760,1),\n",
    "#                             ('e_51.539586_13.956551.tiff',529,614,1),\n",
    "#                             ('e_51.539586_13.956551.tiff',367,820,1),\n",
    "#                             ('e_51.539586_13.956551.tiff', 241,773,0),\n",
    "#                             ('e_51.539586_13.956551.tiff',644,587,0),\n",
    "#                             ('e_51.539586_13.956551.tiff',443,596,0),\n",
    "#                             ('e_51.539586_13.956551.tiff',434,990,0),\n",
    "#                             ('e_51.539586_13.956551.tiff',487,246,0),\n",
    "#                             ('e_51.539586_13.956551.tiff',76,494,0),\n",
    "#                             ('e_51.539586_13.956551.tiff',93,510,0),\n",
    "#                             ('e_51.539586_13.956551.tiff',328,680,0),\n",
    "#                             ('e_51.539586_13.956551.tiff',65,463,0),\n",
    "#                             ('e_52.613_14.225.tiff',613,816,1),\n",
    "#                             ('e_52.613_14.225.tiff',277,276,0),\n",
    "#                             ('e_52.613_14.225.tiff',467,595,0),\n",
    "#                             ('e_52.65538_14.17173.tiff',859,864,0),\n",
    "#                             #('../data/testing_samples/e_51.72116_11.949889.tiff',786,419),\n",
    "#                             #('../data/testing_samples/e_51.72116_11.949889.tiff',395,726),\n",
    "#                             #('../data/testing_samples/e_51.72116_11.949889.tiff',562,952)\n",
    "#                             #('../data/testing_samples/e_51.539586_13.956551.tiff',254,418),\n",
    "#                             #('../data/testing_samples/e_51.539586_13.956551.tiff',476,477),\n",
    "#\n",
    "#\n",
    "#                             ],centimages)\n",
    "#centers= np.asarray([centimages['e_51.539586_13.956551.tiff'][241][773],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][367][820],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][529][614],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][529][614],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][644][587],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][598][760],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][443][596],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][434][990],\n",
    "#          centimages['e_52.693698_14.239078.tiff'][512][662],\n",
    "#          centimages['e_52.693698_14.239078.tiff'][481][555],\n",
    "#          centimages['e_52.613_14.225.tiff'][613][816],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][487][246],\n",
    "#          centimages['e_51.72116_11.949889.tiff'][60][821],\n",
    "#          centimages['e_52.65538_14.17173.tiff'][859],[864],\n",
    "#          centimages['e_51.72116_11.949889.tiff'][750][241],\n",
    "#          #('../data/testing_samples/e_51.72116_11.949889.tiff',786,419),\n",
    "#          #('../data/testing_samples/e_51.539586_13.956551.tiff',476,477),\n",
    "#          #('../data/testing_samples/e_51.539586_13.956551.tiff',254,418),\n",
    "#          #('../data/testing_samples/e_51.72116_11.949889.tiff',395,726),\n",
    "#          #('../data/testing_samples/e_51.72116_11.949889.tiff',562,952)\n",
    "#          centimages['e_51.72116_11.949889.tiff'][590][823],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][76][494],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][93][510],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][328][680],\n",
    "#          centimages['e_51.72116_11.949889.tiff'][606][688],\n",
    "#          centimages['e_51.539586_13.956551.tiff'][65,][463],\n",
    "#          centimages['e_52.613_14.225.tiff'][277][276]])\n",
    "\n",
    "#a = torch.cuda.memory_allocated(0)\n",
    "#r= torch.cuda.memory_reserved(0)\n",
    "#print(f'memory allocated:{a/(1024.0*1024.0*1024.0)}/ memory reserved:{r/(1024.0*1024.0*1024.0)}')\n",
    "#a = torch.cuda.memory_allocated(0)\n",
    "#r= torch.cuda.memory_reserved(0)\n",
    "#print(f'memory allocated:{a/(1024.0*1024.0*1024.0)}/ memory reserved:{r/(1024.0*1024.0*1024.0)}')\n",
    "#print (centers.shape)\n",
    "#\n",
    "#knn =FaissKNeighbors(k=1,p=2)\n",
    "#knn.fit(centers,labels)\n",
    "#PredictClusters(data_path,onlyfiles,knn,mean,std,save=False)\n",
    "#PredictClusters1(data_path,onlyfiles,centers,labels,mean,std,save=False)\n",
    "#num_clusters = 7\n",
    "#_, cluster_centers = kmeans(\n",
    "#    X=images, num_clusters=0, distance='euclidean', device=torch.device('cuda:0'),tol=1e-08,centers=centers  #centers beyond num_clusters will not be changed\n",
    "#)\n",
    "#mapped_centers1= cluster_centers*std+mean\n",
    "#PredictClusters1(data_path,onlyfiles,cluster_centers,mapped_centers1,mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean= np.zeros(12,'float64')\n",
    "std = np.ones(12,'float64')\n",
    "mean = [2279.1047, 2011.3107, 1923.4674, 1756.1125, 2057.2666, 3134.0662,\n",
    "        3605.1943, 3540.2402, 3875.7695, 1767.3289, 2826.0640,\n",
    "        2066.8394]\n",
    "std = [180.2996, 240.9028, 288.8739, 438.9496, 419.7839, 677.7819, 873.3377,\n",
    "        886.2139, 949.8568, 258.4645, 731.5524, 677.3787]\n",
    "normalize= transforms.Normalize(mean,std,inplace=True)\n",
    "\n",
    "pixnn= pixelwise(12)\n",
    "\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "r= torch.cuda.memory_reserved(0)\n",
    "print(f'memory allocated:{a/(1024.0*1024.0*1024.0)}/ memory reserved:{r/(1024.0*1024.0*1024.0)}')\n",
    "pixnn=pixnn.to('cuda:0')\n",
    "trainpixelwisenn(pixnn,centers,labels,normalize, 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifypixelwise(data_path,onlyfiles,pixnn,normalize,plot=True, save=False)\n",
    "\n",
    "torch.save(pixnn.state_dict(), '../data/pixnn/trained_separately/pixnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old kmeans code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#\n",
    "#\n",
    "#mapped_centers= mapped_centers1\n",
    "#mapped_centers[5]=torch.from_numpy(np.zeros(12))\n",
    "#mapped_centers[1]=torch.from_numpy(10000.0*np.ones(12))\n",
    "#mapped_centers[6]=mapped_centers[5]\n",
    "#mapped_centers[7]=mapped_centers[5]\n",
    "#mapped_centers[8]=mapped_centers[5]\n",
    "#mapped_centers[2]=mapped_centers[1]\n",
    "#mapped_centers[9]=mapped_centers[1]\n",
    "#mapped_centers[4]= mapped_centers[1]\n",
    "#mapped_centers[10]=mapped_centers[5]\n",
    "#mapped_centers[3]=mapped_centers[5]\n",
    "#mapped_centers[0]=mapped_centers[5]\n",
    "#mapped_centers[11]=mapped_centers[1]\n",
    "#mapped_centers[12]= mapped_centers[5]\n",
    "#mapped_centers[13]= mapped_centers[1]\n",
    "#mapped_centers[14]= mapped_centers[5]\n",
    "#mapped_centers[15]= mapped_centers[5]\n",
    "#mapped_centers[16]= mapped_centers[5]\n",
    "#mapped_centers[17]= mapped_centers[5]\n",
    "#\n",
    "#mapped_centers[18]= mapped_centers[1]\n",
    "#mapped_centers[21]=mapped_centers[5]\n",
    "#\n",
    "#mapped_centers[19]= mapped_centers[5]\n",
    "#mapped_centers[20]= mapped_centers[5]\n",
    "#mapped_centers[22]=mapped_centers[5]\n",
    "#\n",
    "#PredictClusters(data_path,onlyfiles,cluster_centers,mapped_centers,mean,std,save=True)\n",
    "#filehandler = open(f'../data/params.pkl', 'wb')\n",
    "#pickle.dump({'mean':mean,'std': std,'cluster_centers':cluster_centers,'mapped_centers':mapped_centers}, filehandler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
